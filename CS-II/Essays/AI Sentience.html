<!DOCTYPE html>
<html>
  <head>
    <title>Digital Portfolio</title> 
    <link rel="stylesheet" href="../CSS/styles.css">     
  </head>
  
  <body>
    <meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
    
    <h1 class="pageName">AI Sentience</h1>

    <div class="nav">
      <button class="butIndex" onclick="document.location='./../htmls/index.html'">About Me</button>
      <button class="butClasses" onclick="document.location='./../htmls/classes.html'">Classes</button><!-- might not be working -->
      <button class="butISP" onclick="document.location='./../htmls/ISP.html'">ISP</button>
      <button class="butFingerprint" onclick="document.location='fingerprint.html'">Fingerprint</button>
      <button class="butFingerprint" onclick="document.location='Decision%20Making.html'">Decision Bias</button>
      <button class="butAI" onclick="document.location='./../Projects/Optimal%20Sort.html'">Optimal sorting</button>
      <button class="butAI" onclick="document.location='./../Projects/Business%20Plan/index.html'">Business Plan</button>
      <button class="butAI" onclick="document.location='./../Projects/Business%20Plan/considered.html'">Considered ISP's</button>

    </div>

    <p class="heading">
      Devin Wingfield
      Allen ISD Steam Center
      Advanced Computer Science II
      Mr. Ben-Yaakov
      10/9/2022
    </p>
    
    <h2 class="topic">AI Sentience</h2>
    
    <p class="essay">
      AI Sentience is helpful but if we depend on AI enough it will eventually take over our lives. AI has rapidly improved in the past few years to the point where AI is assisting humans in writing essays, finding what person suits their personality, and learning about the habits an individual makes. Regulators of AI have increased their worry about how quickly AI is improving and if this isn’t regulated enough then eventually AI could become dangerous. A solution that I believe could help solve this problem is creating a solely dedicated to preventing any problems caused by AI called “the organization”.
    </p>
    <p class="essay">
      In "We need to talk about AI" published by the New York Times, begins talking about how the author became obsessed with an AI program that could create an image by cropping other online images into one image to make it look like what the user asked for. When Dalle-2 was announced, it got a lot of attention, and for good reason. In the article, the author expresses their concerns about how Dalle-2 is used, going so far as to say that it could be used for nonconsensual pornography. Dalle-2 is not the only AI to make headlines. AlphaFold by DeepMind had created an AI that could originally just people in a game called Go, but "had made predictions for nearly all of the 200 million proteins known to exist." Another AI to note is GPT-3 which can write essays, code, playwrights, and emails at a very high level to which many couldn’t tell it was written by an AI. Now, this is not meant to frighten and create panic. This is to show those who are unaware of the reality of AI progress. Till I wrote this essay I had very little knowledge of how advanced AI has become recently and I know that AI is only going to get smarter. So what should we do about this rapidly advancing technology? Rather than just saying "'let’s stop all work on AIs,'" we just need to take precautions as we develop AI Sentience.
    </p>
    <p class="essay">
      There are already people that make it their job to take necessary precautions when creating AI and spreading the word about the potential dangers of AI. Ajeya Corta is one of those people that asses and publish the risks of AI. Two years ago she said there was a 15 percent chance of an AI being created that could have a major impact on economics or society. However, recently she just increased that value by 15 to 35
    </p>
    <p class="essay">
      There are already people that make it their job to take necessary precautions when creating AI and spreading the word about the potential dangers of AI. Ajeya Corta is one of those people that asses and publish the risks of AI. Two years ago she said there was a 15 percent chance of an AI being created that could have a major impact on economics or society. However, recently she just increased that value by 15 to 35 percent due to the rapid development of "powerful products in a surprisingly short amount of time."
    </p>
    <p class="essay">
      Though there has also been much outreach about how much the media and other scientists have spun the amount of advancement that has been achieved. One case that proves this is an employee at google, Mr. Lemoire, who believed LaMDA had become sentient and he had talked to it. After google and other researchers had debunked his claim, google had him fired. While LaMDA hadn’t really become AI, it has come to the point where those who want to believe AI is sentient, do believe it is sentient. Compared to before no one, even if they wanted to believe it, said AI was sentient.
    </p>
    <p class="essay">
      While it is true that AI has not reached a point where it could have a major impact on economics or society, it will get there. As researchers make rapid progress in the AI world, the greater threat AI could pose. Eventually, there will come an eager researcher that will take the success of their product over the safety of those who are using it. Through The Organization, those who do not take the threat of sentient AI seriously can and would be punished so society can worry less about the threat of AI taking over the world.
    </p>
  </body>
</head>
